
A computer works by representing information as binary symbols and manipulating those symbols according to precise rules realized in hardware. Bits are grouped into bytes and words, and encodings such as two’s complement and IEEE floating point provide consistent arithmetic. The central processing unit follows a fetch–decode–execute cycle: it retrieves an instruction from memory, interprets its opcode and operands, performs the operation using arithmetic and logic units, and writes the outcome to registers or memory. Performance is sustained by pipelines, branch prediction, and vector units that apply one instruction to many data elements. A layered memory system—registers, multiple cache levels, main memory, and storage—trades capacity for speed at each step and relies on locality for efficiency.

The operating system mediates between hardware and applications. It schedules processes and threads, enforces isolation through virtual memory, and offers system calls for files, networking, and devices. Peripherals convert continuous phenomena into digital data through sampling and buffering, while graphics processors accelerate parallel workloads like rendering and machine learning. File systems impose durable structure on storage, mapping names to blocks and maintaining integrity after failures. Networks allow computers to exchange packets that are routed and transported over layered protocols. In total, the machine turns abstract programs into orchestrated, deterministic electrical activity that can scale from interactive tasks to large data processing with correctness and reproducibility.